########################################
##
## This R file introduces importance sampling
##
########################################


muX<-10 ## Set the mean of our normal
sdX<-1 ## Set the standard deviation of our normal
dfY<-5 ## Set the degrees of freedom of our proposal t-distribution
n<-100000 ## How many samples we want
h<-function(x){x^2} ## This is our h(X) that we are interested in

Y<-rt(n=n,df=dfY) ## simulate from the t-distribution
inside<-h(Y)*dnorm(Y,mean=muX,sd=sdX)/dt(Y,df=dfY) ## Calculate the values
mean(inside)
muX^2+sdX^2 #Truth

## Now calculate the MC.se

sd(inside)/sqrt(n) ## This is pretty large

x.seq = seq(0, 20, length.out = 100)
plot(dnorm(x.seq, mean = muX, sd = sdX) ~ x.seq, type = "l")
lines(dt(x.seq, df = dfY) ~ x.seq, lty = 2, col = "red")

## Let's try to do better by using a smarter density

plot(dnorm(x.seq, mean = muX, sd = sdX) ~ x.seq, type = "l")
lines(dcauchy(x.seq, location = muX, scale = 1) ~ x.seq, lty = 2, col = "red")

Y<-rcauchy(n=n, location = muX) ## simulate from the cauchy distribution
inside<-h(Y)*dnorm(Y,mean=muX,sd=sdX)/dcauchy(Y, location = muX) ## Calculate the values
mean(inside)
muX^2+sdX^2 #Truth

sd(inside)/sqrt(n) ## This is much smaller, which is good







# Now consider calculating an integral ------------------------------------
## integral from 0 to 1 of exp(-x)/(1 + x^2)dx


n<-10000
h<-function(x){exp(-x)/(1+x^2)}
theta<-numeric(5)
theta_se<-numeric(5)

# Uniform
Y<-runif(n)
Z<-h(Y)*dunif(Y)/dunif(Y)
theta[1]<-mean(Z)
theta_se[1]<-sd(Z)/sqrt(n)

# Exponential
Y<-rexp(n)
Z<-h(Y)*dunif(Y)/dexp(Y)
theta[2]<-mean(Z)
theta_se[2]<-sd(Z)/sqrt(n)

# Cauchy
Y<-rcauchy(n)
Z<-h(Y)*dunif(Y)/dcauchy(Y)
theta[3]<-mean(Z,na.rm=TRUE)
theta_se[3]<-sd(Z,na.rm=TRUE)/sqrt(n-sum(is.na(Z)))

# G3
U<-runif(n)
Y<- -log(1-U*(1-exp(-1)))
g3<-function(x){exp(-x)/(1-exp(-1))*(x>0)*(x<1)}
Z<-h(Y)*dunif(Y)/g3(Y)
theta[4]<-mean(Z)
theta_se[4]<-sd(Z)/sqrt(n)

# G4
U<-runif(n)
Y<- tan(U*pi/4)
g4<-function(x){4/(pi*(1+x^2))*(x>0)*(x<1)}
Z<-h(Y)*dunif(Y)/g4(Y)
theta[5]<-mean(Z)
theta_se[5]<-sd(Z)/sqrt(n)

# Results
data.frame(theta=theta,SE=theta_se)
















# Now do some bootstrapping -----------------------------------------------

data.obs = rnorm(100, mean = 3, sd = 2) ## Observe some data from normal dist
## Get estimate for mu and sigma^2
mu.hat = mean(data.obs)
sigma.hat = sd(data.obs)

K = 10000 ## Number of bootstrap samples

mu.boot = rep(NA, K)
for(i in 1:K){
  boot.sample = rnorm(K, mean = mu.hat, sd = sigma.hat)
  mu.boot[i] = mean(boot.sample)
}

## The above for loop is slow. It's faster to do the following:
boot.sample = matrix(rnorm(100*K, mean = mu.hat, sd = sigma.hat),
                     nrow = K)
mu.boot = rowMeans(boot.sample)

hist(mu.boot, prob = T, breaks = 30)
curve(dnorm(x, mean = 3, sd = 2/sqrt(100)), add = TRUE)


